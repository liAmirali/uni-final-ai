from typing import List, Dict, TypedDict
from langchain.output_parsers import PydanticOutputParser
import json
import os
from openai import OpenAI
from openai.types.chat import (
    ChatCompletionAssistantMessageParam,
    ChatCompletionMessageParam,
    ChatCompletionSystemMessageParam,
    ChatCompletionUserMessageParam,
)
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import InMemorySaver
from dotenv import load_dotenv
from graph.output.models import MentalHealthAnalysis, MentalHealthIndicator

load_dotenv()


class ConversationState(TypedDict):
    messages: List
    current_question_index: int
    user_responses: List[str]
    questions: List[str]
    mindmap: Dict
    mental_health_subjects: Dict
    analysis: MentalHealthAnalysis | None


class LLMCaller:
    def __init__(self, client: OpenAI, model: str):
        self.client = client
        self.model = model

    def _role(self, m):
        return "assistant" if m.type == "ai" else "user" if m.type == "human" else "system"
    
    def _text(self, content) -> str:
        if isinstance(content, str):
            return content
        if isinstance(content, list):
            parts = []
            for p in content:
                if isinstance(p, dict):
                    parts.append(p.get("text") or p.get("content") or "")
                else:
                    parts.append(str(p))
            return "\n".join(x for x in parts if x)
        return str(content)

    def _build_payload(self, messages: List) -> List[ChatCompletionMessageParam]:
        payload = []
        for m in messages:
            if isinstance(m, SystemMessage):
                payload.append(ChatCompletionSystemMessageParam(
                    role="system",
                    content=self._text(m),
                ))
            elif isinstance(m, HumanMessage):
                payload.append(ChatCompletionUserMessageParam(
                    role="user",
                    content=self._text(m),
                ))
            elif isinstance(m, AIMessage):
                payload.append(ChatCompletionAssistantMessageParam(
                    role="assistant",
                    content=self._text(m),
                ))
        return payload

    def invoke(self, messages: List, model: str | None = None):
        payload: List[ChatCompletionMessageParam] = self._build_payload(messages)
        model_to_use = model or self.model
        resp = self.client.chat.completions.create(
            model=model_to_use,
            temperature=0.7,
            top_p=0.9,
            messages=payload,
        )
        # Return a response object that mimics langchain's response
        class Response:
            def __init__(self, content):
                self.content = content
        return Response(resp.choices[0].message.content)


class TherapistBot:
    def __init__(self):
        # Initialize Aval AI client
        AVALAI_BASE_URL = os.getenv("AVALAI_BASE_URL", "https://api.avalai.ir/v1")
        AVALAI_MODEL = os.getenv("AVALAI_MODEL", "gpt-4o")
        
        client = OpenAI(
            api_key=os.getenv("AVALAI_API_KEY"),
            base_url=AVALAI_BASE_URL,
        )
        
        self.chat = LLMCaller(client, AVALAI_MODEL)

        # Load mental health indicators from mindmap.json
        with open("knowledge_base/mindmap.json", "r", encoding="utf-8") as f:
            self.mindmap = json.load(f)

        # Load mental health indicators description
        with open("knowledge_base/mental_health_subjects.json", "r", encoding="utf-8") as f:
            self.mental_health_subjects = json.load(f)

        # self.questions = [
        #     "Ø§Ø² Ù…Ø³ÛŒØ±ÛŒ Ú©Ù‡ Ø¯Ø± Ø²Ù†Ø¯Ú¯ÛŒ Ø·ÛŒ Ú©Ø±Ø¯Ù‡ Ø§ÛŒØ¯ Ùˆ Ù…Ø±ÙˆØ± Ú¯Ø°Ø´ØªÙ‡ Ú†Ù‡ Ø§Ø­Ø³Ø§Ø³ÛŒ Ø¯Ø§Ø±ÛŒØ¯ØŸ",
        #     "Ø¯ÙˆØ±Ù‡ Ø³Ø§Ù„Ù…Ù†Ø¯ÛŒ Ø±Ø§ ØªÙˆØµÛŒÙ Ú©Ù†ÛŒØ¯",
        #     "Ø±Ø§Ø¶ÛŒ Ù‡Ø³ØªÛŒØ¯ Ø§Ø² Ø§ÛŒÙ† Ø¯ÙˆØ±Ù‡ Ø§Ø² Ø²Ù†Ø¯Ú¯ÛŒ ØªÙˆÙ†ØŸ",
        #     "Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† Ø±Ù†Ø¬ Ùˆ Ú†Ø§Ù„Ø´ Ø³Ø§Ù„Ù…Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§ Ú†ÛŒ Ø¨ÙˆØ¯Ù‡ØŸ",
        #     "Ø¯Ø± Ø±Ø§Ø¨Ø·Ù‡ Ø¨Ø§ Ú©Ø§Ù‡Ø´ ØªÙˆØ§Ù†Ù…Ù†Ø¯ÛŒ Ù‡Ø§ÛŒ Ø¯ÙˆØ±Ù‡ Ø³Ø§Ù„Ù…Ù†Ø¯ÛŒ Ú†Ù‡ Ø§Ø­Ø³Ø§Ø³ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø§ÛŒØ¯ Ùˆ Ú†Ù‡ Ú©Ø§Ø± Ú©Ø±Ø¯ÛŒØ¯ØŸ",
        #     "Ø´Ø¯Ù‡ Ø§Ø² Ø¯ÙˆØ³ØªØ§Ù† Ùˆ Ù‡Ù…Ø³Ù† Ùˆ Ø³Ø§Ù„Ø§Ù† Ø´Ù…Ø§ Ú©Ø³ÛŒ ÙÙˆØª Ú©Ù†Ù‡ Ùˆ Ø´Ù…Ø§ Ø®ÛŒÙ„ÛŒ Ø§Ø°ÛŒØª Ø¨Ø´ÛŒØ¯ØŸ",
        #     "Ø¨Ø§Ø²Ù†Ø´Ø³ØªÚ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§ Ú†Ù‡ ØªØ¬Ø±Ø¨Ù‡ Ø§ÛŒ Ø¯Ø§Ø´ØªÙ‡ØŸ",
        #     "Ø¯Ø± Ø§ÛŒÙ† Ø¯ÙˆØ±Ù‡ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ú©Ø§Ù‡Ø´ ÙØ¹Ø§Ù„ÛŒØª Ø´ØºÙ„ÛŒ Ù…Ø´Ú©Ù„ Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ù¾ÛŒØ´ Ù†ÛŒØ§Ù…Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§ØŸ",
        #     "Ø§ÛŒÙ†Ú©Ù‡ Ø³Ø¨Ú© Ø²Ù†Ø¯Ú¯ÛŒ ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡ Ø¯Ø± Ø³Ø§Ù„Ù…Ù†Ø¯ÛŒ Ú†Ù‡ ØªØ¬Ø±Ø¨Ù‡ Ø§ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§ØŸ",
        # ]
        
        self.questions = [
            "Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ú†Ø§Ù„Ø´â€ŒØªÙˆÙ† Ø¯Ø± Ø§ÛŒÙ† Ø¯ÙˆØ±Ø§Ù† Ú†ÛŒÙ‡ØŸ",
            "Ø¨Ù‡ Ù†Ø¸Ø±ØªÙˆÙ† Ø§Ú¯Ø± ÙˆØ¶Ø¹ÛŒØª Ù…Ø§Ù„ÛŒ Ø¨Ù‡ Ú¯ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø¨ÙˆØ¯ Ú©Ù‡ Ù…Ø¬Ø¨ÙˆØ± Ù†Ø¨ÙˆØ¯ÛŒØ¯ Ú©Ø§Ø± Ú©Ù†ÛŒØ¯ØŒ Ú†Ù‡ Ù…ÛŒâ€ŒØ´Ø¯ØŸ",
            "Ø¨Ù‡ Ù†Ø¸Ø±ØªÙˆÙ† Ú†Ø±Ø§ Ø§ÛŒÙ† Ø§ØªÙØ§Ù‚ Ù…ÛŒâ€ŒØ§ÙØªÙ‡ØŸ",
            "Ø§Ø­Ø³Ø§Ø³ Ø´Ù…Ø§ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø§ÛŒÙ† Ø´Ø±Ø§ÛŒØ· Ù…Ø§Ù„ÛŒ Ú†ÛŒØ³ØªØŸ",
            "Ø¢ÛŒØ§ Ú©Ø³ÛŒ Ø§Ø² Ø¯ÙˆØ³ØªØ§Ù† ÛŒØ§ Ø§Ù‚ÙˆØ§Ù… Ø´Ù…Ø§ Ø±Ø§ Ø·ÛŒ Ø§ÛŒÙ† Ø³Ø§Ù„â€ŒÙ‡Ø§ Ø§Ø² Ø¯Ø³Øª Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒØ¯ØŸ",
            "Ù†Ø¸Ø± Ø´Ù…Ø§ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø²Ø´Ú©ÛŒ Ú†ÛŒØ³ØªØŸ",
            "Ø­Ø§Ù„Ø§ Ø¯Ø± Ø§ÛŒÙ† Ø³Ù† Ùˆ Ø³Ø§Ù„ØŒ Ø¨Ú†Ù‡â€ŒÙ‡Ø§ Ø§Ø²Ø¯ÙˆØ§Ø¬ Ú©Ø±Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ø®ÙˆØ¯ØªØ§Ù† Ùˆ Ù‡Ù…Ø³Ø±ØªØ§Ù† ØªÙ†Ù‡Ø§ Ù‡Ø³ØªÛŒØ¯ØŸ",
            "Ø¢ÛŒØ§ Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒâ€ŒØªØ§Ù† Ú©Ù…Ø±Ù†Ú¯â€ŒØªØ± Ø´Ø¯Ù‡ØŸ",
            "Ø¨Ø§ Ø§ÛŒÙ† Ø­Ø§Ù„ØŒ Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒÚ¯Ø°Ø±Ø§Ù†ÛŒØ¯ØŸ",
            "Ø¯Ø± Ø¢Ø®Ø±ØŒ Ú†Ù‡ Ù¾ÛŒØ§Ù…ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬ÙˆØ§Ù†â€ŒÙ‡Ø§ Ø¯Ø§Ø±ÛŒØ¯ØŸ"
        ]

        # Create the graph
        self.graph = self._create_graph()

    def _create_graph(self):
        """Create the conversation graph"""
        workflow = StateGraph(ConversationState)

        # Add nodes
        workflow.add_node("greet", self._greet_user)
        workflow.add_node("ask_question", self._ask_question)
        workflow.add_node("get_answer", self._get_answer)
        workflow.add_node("analyze_answer", self._analyze_answer)

        # Add edges
        workflow.set_entry_point("greet")
        workflow.add_edge("greet", "ask_question")
        workflow.add_edge("ask_question", "get_answer")
        workflow.add_edge("get_answer", "analyze_answer")
        workflow.add_conditional_edges(
            "analyze_answer",
            self._should_continue_questions,
            {
                "continue": "ask_question",
                "finish": END,
            },
        )

        return workflow.compile()

    def _greet_user(self, state: ConversationState) -> ConversationState:
        """Greet the user and initialize the conversation"""
        print("ðŸŒ¸ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯ Ø¨Ù‡ Ø³ÛŒØ³ØªÙ… Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø³Ù„Ø§Ù…Øª Ø±ÙˆØ§Ù† ðŸŒ¸")
        print("=" * 50)
        print()

        greeting = f"Ø³Ù„Ø§Ù…! Ù…Ù† {len(self.questions)} Ø³ÙˆØ§Ù„ Ø§Ø² Ø´Ù…Ø§ Ø®ÙˆØ§Ù‡Ù… Ù¾Ø±Ø³ÛŒØ¯ ØªØ§ ÙˆØ¶Ø¹ÛŒØª Ø³Ù„Ø§Ù…Øª Ø±ÙˆØ§Ù† Ø´Ù…Ø§ Ø±Ø§ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ù†Ù…. Ø¢ÛŒØ§ Ø¢Ù…Ø§Ø¯Ù‡ Ù‡Ø³ØªÛŒØ¯ØŸ"
        print(f"ðŸ¤– {greeting}")

        state["messages"] = [AIMessage(content=greeting)]
        state["current_question_index"] = 0
        state["user_responses"] = []
        state["questions"] = self.questions
        state["mindmap"] = self.mindmap
        state["mental_health_subjects"] = self.mental_health_subjects
        state["analysis"] = None

        return state

    def _ask_question(self, state: ConversationState) -> ConversationState:
        """Ask the current question"""
        current_index = state["current_question_index"]
        question = state["questions"][current_index]

        question_text = (
            f"Ø³ÙˆØ§Ù„ {current_index+1} Ø§Ø² {len(state['questions'])}:\n{question}"
        )
        print(f"ðŸ¤– {question_text}")

        state["messages"].append(AIMessage(content=question_text))
        return state

    def _get_answer(self, state: ConversationState) -> ConversationState:
        """Get user's answer"""
        print()
        response = input("Ø´Ù…Ø§: ")

        if response.lower() in ["Ø®Ø±ÙˆØ¬", "exit", "quit"]:
            print("Ø®Ø¯Ø§Ø­Ø§ÙØ¸!")
            state["current_question_index"] = len(state["questions"])  # Force end
            return state

        state["messages"].append(HumanMessage(content=response))
        state["user_responses"].append(response)
        print()
        return state

    def _analyze_answer(self, state: ConversationState) -> ConversationState:
        """Analyze the current answer using LLM"""
        current_index = state["current_question_index"]
        current_response = state["user_responses"][-1]
        current_question = state["questions"][current_index]

        print("ðŸ” Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ù¾Ø§Ø³Ø®...")

        system_prompt = """
        Ø´Ù…Ø§ ÛŒÚ© Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ Ù…ØªØ®ØµØµ Ø³Ø§Ù„Ù…Ù†Ø¯Ø§Ù† Ù‡Ø³ØªÛŒØ¯. Ù„Ø·ÙØ§Ù‹ Ù¾Ø§Ø³Ø® Ø²ÛŒØ± Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯ Ùˆ Ù†Ø´Ø§Ù†Ú¯Ø±Ù‡Ø§ÛŒ Ø³Ù„Ø§Ù…Øª Ø±ÙˆØ§Ù† Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯.

        Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ø´Ø§Ù†Ú¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡ØŒ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù†ÛŒØ¯:
        - aspect: "emotion" (Ù‡ÛŒØ¬Ø§Ù†)ØŒ "belief" (Ø¨Ø§ÙˆØ±)ØŒ ÛŒØ§ "behavior" (Ø±ÙØªØ§Ø±)
        - subject: Ù…ÙˆØ¶ÙˆØ¹ Ø¯Ù‚ÛŒÙ‚ Ø§Ø² Ù†Ù‚Ø´Ù‡ Ø°Ù‡Ù†ÛŒ
        - based_on_answer: Ø¨Ø®Ø´ÛŒ Ø§Ø² Ù¾Ø§Ø³Ø® Ú©Ø§Ø±Ø¨Ø± Ú©Ù‡ Ø§ÛŒÙ† Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ù† Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡
        - reasoning: ØªÙˆØ¶ÛŒØ­ Ø§ÛŒÙ†Ú©Ù‡ Ú†Ø±Ø§ Ø§ÛŒÙ† Ù†Ø´Ø§Ù†Ú¯Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø§Ø² Ù…Ù†Ø¸Ù‚ Ùˆ ØªØ­Ù„ÛŒÙ„ Ú¯Ø§Ù… Ø¨Ù‡ Ú¯Ø§Ù… Ù¾Ø§Ø³Ø® Ú©Ø§Ø±Ø¨Ø±

        Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ Ù…ØªØ®ØµØµ Ø³Ø§Ù„Ù…Ù†Ø¯Ø§Ù†ØŒ Ù¾Ø§Ø³Ø® Ù‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¬Ø§Ù…Ø¹ Ùˆ Ø¯Ù‚ÛŒÙ‚ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯ Ùˆ Ù†Ø´Ø§Ù†Ú¯Ø±Ù‡Ø§ÛŒ Ø³Ù„Ø§Ù…Øª Ø±ÙˆØ§Ù† Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯.
        Ú¯Ø§Ù… Ø¨Ù‡ Ú¯Ø§Ù… Ø¬ÙˆØ§Ø¨ Ù‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯ Ùˆ Ø¯Ù„Ø§ÛŒÙ„ Ù…Ù†Ø·Ù‚ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø±Ø§ Ø¨ÛŒØ§Ù† Ú©Ù†ÛŒØ¯.
        """

        analysis_prompt = f"""
            Ø³ÙˆØ§Ù„: {current_question}
            Ù¾Ø§Ø³Ø® Ú©Ø§Ø±Ø¨Ø±: {current_response}

            Ù†Ø´Ø§Ù†Ú¯Ø±Ù‡Ø§ÛŒ Ø³Ù„Ø§Ù…Øª Ø±ÙˆØ§Ù†:
            {json.dumps(state["mindmap"], ensure_ascii=False, indent=2)}

            ØªÙˆØ¶ÛŒØ­Ø§Øª Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø³Ù„Ø§Ù…Øª Ø±ÙˆØ§Ù†:
            {json.dumps(state["mental_health_subjects"], ensure_ascii=False, indent=2)}

            Ù„Ø·ÙØ§Ù‹ Ù†Ø´Ø§Ù†Ú¯Ø±Ù‡Ø§ÛŒ Ø³Ù„Ø§Ù…Øª Ø±ÙˆØ§Ù† Ø±Ø§ Ø¯Ø± Ø§ÛŒÙ† Ù¾Ø§Ø³Ø® Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯. ÛŒÚ© Ù¾Ø§Ø³Ø® Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ú†Ù†Ø¯ÛŒÙ† Ù†Ø´Ø§Ù†Ú¯Ø± Ø³Ø§Ù„Ù… Ùˆ ÛŒØ§ Ù†Ø§Ø³Ø§Ù„Ù… Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.


            Ù„Ø·ÙØ§Ù‹ Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¯Ø± Ù‚Ø§Ù„Ø¨ JSON Ø²ÛŒØ± Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯:
            {{
                "unhealthy": [
                    {{
                        "aspect": "emotion/belief/behavior",
                        "subject": "Ù…ÙˆØ¶ÙˆØ¹ Ø§Ø² Ù†Ù‚Ø´Ù‡ Ø°Ù‡Ù†ÛŒ",
                        "based_on_answer": "Ø¨Ø®Ø´ÛŒ Ø§Ø² Ù¾Ø§Ø³Ø® Ú©Ø§Ø±Ø¨Ø±",
                        "reasoning": "ØªÙˆØ¶ÛŒØ­ Ø§Ù†ØªØ®Ø§Ø¨"
                    }}
                ],
                "healthy": [
                    {{
                        "aspect": "emotion/belief/behavior", 
                        "subject": "Ù…ÙˆØ¶ÙˆØ¹ Ø§Ø² Ù†Ù‚Ø´Ù‡ Ø°Ù‡Ù†ÛŒ",
                        "based_on_answer": "Ø¨Ø®Ø´ÛŒ Ø§Ø² Ù¾Ø§Ø³Ø® Ú©Ø§Ø±Ø¨Ø±",
                        "reasoning": "ØªÙˆØ¶ÛŒØ­ Ø§Ù†ØªØ®Ø§Ø¨"
                    }}
                ]
            }}
            """

        try:
            response = self.chat.invoke(
                [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=analysis_prompt),
                ]
            )

            analysis_data = response.content

            if not analysis_data or analysis_data == "":
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„: {response.content}")
                return state

            print(f"ðŸ” ØªØ­Ù„ÛŒÙ„: {analysis_data}")

        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„: {e}")

        # Move to next question
        state["current_question_index"] += 1
        return state

    def _should_continue_questions(self, state: ConversationState) -> str:
        """Determine if we should continue asking questions"""
        current_index = state["current_question_index"]
        if current_index < len(state["questions"]):
            return "continue"
        else:
            return "finish"

    def run(self):
        """Run the graph-based conversation"""
        initial_state = {
            "messages": [],
            "current_question_index": 0,
            "user_responses": [],
            "questions": self.questions,
            "mindmap": self.mindmap,
            "mental_health_subjects": self.mental_health_subjects,
            "analysis": None,
        }

        # Run the graph
        for event in self.graph.stream(initial_state):
            # The graph handles the flow automatically
            pass
